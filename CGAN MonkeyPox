# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1appZbcSKQk_HRUlQ8fe9ACUskzFJr88m
"""

# Unzip the dataset
!unzip /content/drive/MyDrive/monkey_pox_orginal_image.zip

import numpy as np
from PIL import Image
import os
import tensorflow as tf
from tensorflow.keras import layers

# Function to load images and labels from the specified folder
def load_images_with_labels(image_folder, label):
    images = []
    labels = []
    for img_name in os.listdir(image_folder):
        img = Image.open(os.path.join(image_folder, img_name))
        img = img.resize((224, 224))  # Resize to 224x224 pixels
        img = np.array(img)
        img = (img - 127.5) / 127.5  # Normalize to [-1, 1]
        images.append(img)
        labels.append(label)
    return np.array(images), np.array(labels)

# Load images and labels from the Monkeypox class
monkeypox_images, monkeypox_labels = load_images_with_labels('/content/monkey_pox_orginal_image', 1)

# Define the generator model with conditional input
def build_generator():
    noise_input = layers.Input(shape=(100,))
    label_input = layers.Input(shape=(1,))

    label_embedding = layers.Embedding(input_dim=2, output_dim=100)(label_input)
    label_embedding = layers.Flatten()(label_embedding)

    model_input = layers.Concatenate()([noise_input, label_embedding])

    x = layers.Dense(128)(model_input)
    x = layers.LeakyReLU(alpha=0.2)(x)
    x = layers.Dense(256)(x)
    x = layers.LeakyReLU(alpha=0.2)(x)
    x = layers.Dense(512)(x)
    x = layers.LeakyReLU(alpha=0.2)(x)
    x = layers.Dense(224 * 224 * 3, activation='tanh')(x)
    x = layers.Reshape((224, 224, 3))(x)

    return tf.keras.Model([noise_input, label_input], x)


# Define the discriminator model with conditional input
def build_discriminator():
    img_input = layers.Input(shape=(224, 224, 3))
    label_input = layers.Input(shape=(1,))

    # Process the image
    img = layers.Flatten()(img_input)
    img = layers.Dense(512)(img)
    img = layers.LeakyReLU(alpha=0.2)(img)

    # Process the label
    label = layers.Embedding(input_dim=2, output_dim=512)(label_input)
    label = layers.Flatten()(label)

    # Concatenate image and label
    combined = layers.Concatenate()([img, label])
    combined = layers.Dense(256)(combined)
    combined = layers.LeakyReLU(alpha=0.2)(combined)
    combined = layers.Dense(1, activation='sigmoid')(combined)

    return tf.keras.Model([img_input, label_input], combined)

# Compile the GAN with conditional input
def build_gan(generator, discriminator):
    discriminator.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])
    discriminator.trainable = False

    noise_input = layers.Input(shape=(100,))
    label_input = layers.Input(shape=(1,))

    generated_image = generator([noise_input, label_input])

    gan_output = discriminator([generated_image, label_input])
    gan = tf.keras.Model([noise_input, label_input], gan_output)

    gan.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002))
    return gan

# Build the models
generator = build_generator()
discriminator = build_discriminator()
gan = build_gan(generator, discriminator)

# Function to save generated images during training
def save_images(generator, epoch, gen_labels, output_dir='generated_images'):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    noise = np.random.normal(0, 1, (9, 100))
    generated_images = generator.predict([noise, gen_labels])
    generated_images = 0.5 * generated_images + 0.5

    for i in range(9):
        img_array = (generated_images[i] * 255).astype(np.uint8)
        img = Image.fromarray(img_array)
        img.save(os.path.join(output_dir, f"{epoch}_{i}.jpg"))

def train_gan(gan, generator, discriminator, dataset, labels, epochs=5000, batch_size=32, save_interval=1000):
    half_batch = batch_size // 2

    for epoch in range(epochs):
        # Train the discriminator with real images
        idx = np.random.randint(0, dataset.shape[0], half_batch)
        real_images = dataset[idx]
        real_labels = labels[idx]

        # Generate noise and labels for fake images (half batch size)
        noise = np.random.normal(0, 1, (half_batch, 100))
        gen_labels = np.random.randint(0, 2, (half_batch, 1))
        generated_images = generator.predict([noise, gen_labels])

        # Train the discriminator on real and fake images
        d_loss_real = discriminator.train_on_batch([real_images, real_labels], np.ones((half_batch, 1)))
        d_loss_fake = discriminator.train_on_batch([generated_images, gen_labels], np.zeros((half_batch, 1)))
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        # Train the generator (full batch size)
        noise = np.random.normal(0, 1, (batch_size, 100))
        gen_labels = np.random.randint(0, 2, (batch_size, 1))
        valid_y = np.ones((batch_size, 1))
        g_loss = gan.train_on_batch([noise, gen_labels], valid_y)

        # Ensure all inputs for saving images have matching batch sizes
        if epoch % save_interval == 0:
            print(f"{epoch} [D loss: {d_loss[0]} | D accuracy: {100*d_loss[1]}] [G loss: {g_loss}]")
            save_images(generator, epoch, gen_labels[:9])

def save_images(generator, epoch, gen_labels, output_dir='generated_images'):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    noise = np.random.normal(0, 1, (9, 100))
    generated_images = generator.predict([noise, gen_labels])
    generated_images = 0.5 * generated_images + 0.5  ]

    for i in range(9):
        img_array = (generated_images[i] * 255).astype(np.uint8)
        img = Image.fromarray(img_array)
        img.save(os.path.join(output_dir, f"{epoch}_{i}.jpg"))

# Train the cGAN
train_gan(gan, generator, discriminator, monkeypox_images, monkeypox_labels)

# Generate new images
num_images_to_generate = 1428
noise = np.random.normal(0, 1, (num_images_to_generate, 100))
gen_labels = np.ones((num_images_to_generate, 1))
generated_images = generator.predict([noise, gen_labels])

# Convert and save generated images
output_dir = 'new_monkeypox_images'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

for i, img_array in enumerate(generated_images):
    img_array = (0.5 * img_array + 0.5) * 255  # Rescale to [0, 255]
    img_array = img_array.astype(np.uint8)  # Convert to uint8
    img = Image.fromarray(img_array)
    img.save(os.path.join(output_dir, f"monkeypox_generated_{i}.jpg"))

# Zip the generated images
import shutil
shutil.make_archive('monkeypox_generated_images', 'zip', 'new_monkeypox_images')
